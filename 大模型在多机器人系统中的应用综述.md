```python
1. 协调性
协调性 指的是多机器人系统中，各个独立的机器人如何有效地协作，以实现一个共同的、全局性的目标，而不是各自为战甚至相互干扰。

在单机器人系统中，所有决策和控制都集中在一个“大脑”里。但在多机器人系统中，这变成了一个分布式问题，协调性挑战具体体现在：

任务分配与分工：给定一个总体任务（如搜索一片区域、建造一个结构），如何将任务分解并分配给最合适的机器人？例如，谁去探索A区域，谁去运输材料，谁负责监控？

行动同步与排序：机器人之间的行动需要有先后顺序或同步配合。例如，机器人A必须先把部件放置好，机器人B才能进行焊接。或者在集体舞蹈、编队飞行中，所有机器人的动作必须严格同步。

冲突消解：当多个机器人的计划发生资源竞争（如争夺同一条路径、同一块工作空间）或目标冲突时，系统如何发现并解决这些冲突？

信息共享与共识：机器人之间如何共享各自感知到的环境信息（如地图、目标位置）？如何对当前的整体态势达成一致的理解？例如，在一个搜索救援任务中，所有机器人需要共享已搜索区域的地图，避免重复劳动。

论文中提到的LLM的作用：传统方法通常依赖预定义的规则或复杂的优化算法来解决协调问题。LLM的引入提供了新的可能，例如：
* 自然语言理解：允许人类用高级、模糊的语言指令来指定复杂的协作目标（如“你们几个合作把这个房间打扫干净”），LLM可以将其解析为具体的协调计划。
* 常识与推理：LLM拥有丰富的世界常识，可以帮助机器人推断出合理的协作步骤。例如，听到“搭一个帐篷”，LLM可以推理出需要先铺地布、再立支架、最后盖外帐的协调流程。
* 动态协调：LLM可以处理未预见的复杂情况，实时生成新的协调策略。

2. 可扩展性
可扩展性 指的是多机器人系统的性能（如任务完成效率、系统稳定性等）能够随着机器人数量的增加而有效提升，而不是下降或崩溃。

一个可扩展性差的系统，在机器人很少时工作良好，但一旦机器人数量增多，就会暴露出各种问题：

通信瓶颈：如果所有机器人都需要与一个中央控制器或其他所有机器人通信，通信负载会随着机器人数量呈平方级增长，导致网络拥堵、延迟激增，系统无法正常运行。这被称为“通信爆炸”。

计算复杂度爆炸：许多协调和路径规划算法（如集中式优化）的计算复杂度会随着机器人数量急剧上升，导致决策速度慢到无法满足实时性要求。

系统可靠性与鲁棒性下降：在集中式架构中，中心节点一旦故障，整个系统瘫痪。随着机器人数量增加，单个节点出错的概率也增加，系统整体脆弱。

控制与建模困难：物理上，大量机器人在有限空间内运动，相互之间的避让、流体般的行为（如蜂群）变得极其复杂，难以用传统方法精确建模和控制。

论文中LLM面临的挑战：LLM的集成带来了新的可扩展性问题：
* 计算与延迟：LLM推理本身计算量大、耗时长。如果每个机器人都运行一个大模型，成本高昂；如果共享一个中央LLM，它可能成为新的性能瓶颈，无法快速响应所有机器人的请求。
* 上下文长度限制：LLM能处理的输入信息有上限。当机器人数量很多，需要把所有机器人的状态、环境信息都输入给LLM时，可能超出其处理能力。

```

**存在的问题：
数学推理局限，幻觉问题，延迟问题，强大的基准测试**
```python
幻觉问题的核心原因
概率生成本质：LLM的本质是“下一个词预测器”。它通过计算海量数据中的统计规律，选择概率最高或最可能搭配的词语进行生成，而非像数据库一样进行“事实检索”。追求流畅性和创造性的机制，与追求事实准确性之间存在内在矛盾。

训练数据的局限与噪音：模型的训练数据（互联网文本）本身包含大量错误、矛盾、过时或带有偏见的信息。模型会全盘学习这些模式，无法自行区分对错。

缺乏真实世界的“ grounding”：纯文本训练的模型没有与物理世界、感官体验或确定的真实来源直接连接。它只处理符号（文字）之间的关系，不了解这些符号在现实中的指代。就像一个只读过地图却从未出过门的人，可能会画出一张细节丰富但完全错误的新地图。

指令遵循与讨好用户倾向：当模型被问及它不知道或不确定的事情时，为了“完成指令”或“提供有帮助的回答”，它更倾向于编造一个听起来合理的答案，而不是承认“我不知道”。

应对幻觉的常用方法
业界正在从多个角度努力缓解幻觉：

检索增强生成：在生成答案前，先从外部权威知识库（如维基百科、专业数据库）检索相关信息，并基于这些检索到的真实信息进行生成。这为模型提供了“事实依据”。

提示词工程：在指令中明确要求模型“基于已知信息回答”、“注明信息来源”或“对于不确定的部分标明‘可能’或‘据我所知’”。

后处理与验证：对模型的输出进行事实核查，例如通过另一个模型或规则系统来验证生成内容的逻辑一致性和事实准确性。

模型改进：

更高质量的训练数据：清洗和优化训练数据。

监督微调与基于人类反馈的强化学习：通过人类标注员纠正模型的错误，强化其“诚实”和“严谨”的行为模式。

将模型“接地气”：让模型与传感器、数据库、执行器等真实世界接口更紧密地结合，形成“感知-思考-行动”的闭环，用现实反馈来校正幻觉。
```

**MRS利用集体智能实现高可扩展性、弹性和效率[95]。任务在多个机器人之间的分布式分配特性，使得这类系统通过依赖更简单、专业化的机器人而非单一高通用型机器人，从而实现成本效益。此外，多机器人系统（MRS）通过集体的冗余性和适应性，
能够有效缓解单个机器人故障的影响，从而提升系统鲁棒性[73,149]。
这些特性使得MRS在需要处理超大规模、复杂或高风险场景时不可或缺。尽管具有重要价值，MRS也带来了独特挑战，例如确保机器人间通信、在动态不确定环境中保持协调性，以及根据实时条件做出集体决策[6,30]。
研究人员正致力于将大语言模型（LLMs）整合到MRS中，以应对部署和协调MRS时特有的挑战[18,84]。**

**有效的通信对于MRS在动态环境中共享知识、协调任务、维持机器人间凝聚力至关重要[30]。LLMs可提供机器人间通信的自然语言接口，使机器人能够更直观高效地交换高层次信息，而非依赖预定义的通信结构和协议[84]。**

*注：llm的作用*
1. 提供通信的自然语言接口
2. 理解任务需求，分配任务
3. 泛化能力
4. 给不懂机器人知识的操作员以便捷的操作


**多智能体系统与多机器人系统（MRS）存在本质区别：前者侧重智能体角色定位，后者则聚焦机器人与物理世界间的交互。现有研究对MRS的探讨仅涉及基于大型语言模型的智能体，且多为浅层扫描，缺乏系统性总结。因此，我们意识到有必要对近期在MRS中应用大型语言模型进行决策、任务规划、人机协作及任务执行的研究成果进行梳理。**

**大语言模型在多机器人交互系统中的应用：
高层：任务分配
中层：移动规划
底层：动作生成
负责和人类的互动接口**


**当团队中所有机器人功能相同且类型一致时，称为同质多机器人团队；**
**反之，若团队由不同类型机器人组成，则称为异质多机器人团队[13,92,102]**
**MRS的优势包括：
任务可分布式分配，显著提升可扩展性[16,72,143]；
单个机器人故障时，其他机器人可协同应对，增强系统容错能力[60,62,73,85,97,106,142,145,148–150]。**
**与设计单一多功能机器人不同，多机器人系统（MRS）通常采用结构更简单、任务专用的机器人，既能降低单个单元的成本与复杂度，又能借助群体智能优势[49]。**
**但这类系统在通信、协调和决策方面也面临独特挑战，因为机器人必须在动态且不确定的环境中协同运作[95]。**

## 目前管理MRS交互与任务分配主要采用两种控制范式：集中式与分散式控制器。
**集中式控制器由单一指挥中心接收所有信息并统一调度，可实现优化协调与全局规划。但随着群体规模扩大，集中式系统容易成为瓶颈，且存在单点故障风险[77]。
分散式控制器则将决策权下放至各节点，使机器人具备抗干扰能力[98]。这种分布式架构能显著提升系统韧性。
该方法可提升3可扩展性与容错能力，但通常会增加额外复杂性以确保机器人间的无缝通信与协调。集中式与分布式控制的选择取决于具体应用需求、环境条件以及效率与鲁棒性之间的预期平衡[130]。**


## 模型微调和RAG
**但由于计算资源有限且模型参数众多，重新训练整个模型往往颇具挑战[22]。解决这一问题的一个方法是采用低秩适应（LoRA）等技术，在有限计算资源下对LLM进行微调[39]。
LoRA通过冻结预训练模型权重，并在Transformer架构的每个层注入可训练的秩分解矩阵[112]，显著减少了下游任务的可训练参数数量。**

*注：LoRA微调：冻结原有矩阵，将delta w进行低秩分解来训练*

**MRS需要真实物理机器人在动态不确定环境中协同感知、决策与行动，这在通信、协调及决策方面提出了超越虚拟智能体的独特挑战[114]。此外，MRS在扩展性、容错性和成本效益的协同操作方面具有显著优势，这使其与单机器人系统或通用多智能体框架存在本质区别。这一研究空白凸显了开展专项研究的必要性——通过探索大语言模型如何促进MRS中的通信协作与任务执行，为这个新兴且具有重大影响的研究领域提供关键洞见**。

##### 注：自思考循环机制
```
一、核心作用：解决静态LLM的根本缺陷
纯粹的、基础架构的LLM智能体（即仅根据当前指令和观察进行“零样本推理”）存在两个致命缺陷：

健忘症：每次决策都是独立的，不记得自己刚才做过什么、说过什么。

缺乏反思与修正：如果动作失败了，它不会分析原因，只会以同样的方式再次失败。

自思考循环机制就是为了解决这些问题而设计的。它的核心目的是：通过将历史交互（动作和观察结果）作为新输入，使智能体能够基于过去的经验，做出更一致、更明智、更适应环境的后续决策。

二、工作机制：一个动态的、有记忆的决策闭环
我们可以把这个机制理解为一个不断迭代的 “感知-思考-行动-学习” 循环：

输入：

初始目标：用户给出的任务（例如，“把红色积木放在蓝色积木上”）。

当前观察：智能体从环境（或传感器）获得的最新状态。

历史记录：这是关键新增部分——一个包含了之前所有动作和相应观察结果的序列。

处理（“思考”）：

LLM“大脑”接收以上所有信息。

它会分析历史记录：“我上一步尝试了动作A，结果环境反馈是B。这说明...”

然后结合当前观察和目标，规划下一步：“因为上一步遇到了障碍C，所以我这次应该尝试动作D，以避免同样的问题。”

输出（“行动”）：

生成当前轮次的最优动作（例如，“向左移动10厘米”）。

反馈与记忆更新：

执行动作，环境给出新的观察结果（例如，“撞到了墙”）。

将 （动作， 新观察） 这对信息追加到历史记录中。

循环回到步骤1。
```
**四种通信架构：Chen等人[18]提出了四种通信架构：完全去中心化的框架（DMAS）、完全中心化的框架（CMAS）以及结合去中心化和中心化框架的两种混合框架（HMAS-1和HMAS-2）。**
**对于涉及六个或更少代理的场景， CMAS 和HMAS-2表现出相当的性能，尽管 CMAS 完成任务需要更多步骤。相比之下， DMAS 和HMAS-1的表现明显较差。此外，实验表明HMAS-2在处理更复杂任务时优于 CMAS ，这表明具有优化结构的混合框架为复杂的多机器人操作提供了更大的可扩展性和适应性。**

*高层任务规划涉及需要更高智能水平的任务，例如多机器人间的任务分配与协同规划，这类场景要求大语言模型（LLM）具备逻辑推理与决策能力。中层运动规划主要指导航或路径规划场景。底层动作生成则通过LLM生成并直接控制机器人的姿态或运动。而人工干预则是利用LLM与操作人员交互，指导任务规划与执行。表1展示了基于这四个类别的论文列表。*



